{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8322ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.6.1\n",
      "joblib version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import joblib\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"joblib version:\", joblib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77c7de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data1 = 'csv_files/mathematics_questions - mathematics_questions (1).csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "677454b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Category\"] == \"Addition, Subtraction\", \"Category\"] = \"Addition\"\n",
    "df.loc[df[\"Category\"] == \"Subtraction\", \"Category\"] = \"Addition\"\n",
    "df.loc[df[\"Category\"] == \"Length measuring \", \"Category\"] = \"Length measuring\"\n",
    "df.loc[df[\"Category\"] == \"Direction\", \"Category\"] = \"Directions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54829036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c16b4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Question    Category\n",
      "0    රුපියල් 125 ක අත්පොතක් සහ රුපියල් 80 ක කොමඩි ප...    Currency\n",
      "1    එක් වෙළඳසැලක සපත්තු කුට්ටමක මිල රු. 2500 ක් වන...    Currency\n",
      "2    එකම වර්ගයේ අභ්‍යාස පොත් 8 ක් සඳහා රුපියල් 520 ...    Currency\n",
      "3    සහෝදරයන් තිදෙනෙකු එකතු වී තම මවට රුපියල් 2400 ...    Currency\n",
      "4    මුදල් පසුම්බියක රුපියල් 20 නෝට්ටු 5 ක්, රුපියල...    Currency\n",
      "..                                                 ...         ...\n",
      "123  නිවසක සිට පුද්ගලයෙකු දකුණට මීටර් 50 ක් ගොස්, ඉ...  Directions\n",
      "124  ක්‍රීඩා පිටියක හතර කොනේ කණු හතරක් සිටුවා ඇත (A...  Directions\n",
      "125  එක්තරා නගරයක පාසල පිහිටා ඇත්තේ ක්‍රීඩාංගනයට උත...  Directions\n",
      "126  A, B, C, D යන ස්ථාන හතරක් එකම සරල රේඛාවක පිහිට...  Directions\n",
      "127   අත් ඔරලෝසුවක් එහි මුහුණත උඩු අතට සිටින සේ මේස...  Directions\n",
      "\n",
      "[128 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's assume df is your existing DataFrame and it has a \"Category\" column\n",
    "\n",
    "# Initialize an empty list to collect sample DataFrames\n",
    "sampled_dfs = []\n",
    "\n",
    "# Get the list of unique categories\n",
    "categories = df['Category'].unique()\n",
    "\n",
    "# Loop over each category and sample 10 rows\n",
    "for cat in categories:\n",
    "    # Filter rows for current category\n",
    "    subset = df[df['Category'] == cat]\n",
    "\n",
    "    # If there are at least 10 rows, randomly sample 10 rows;\n",
    "    # otherwise, take all the rows from that category.\n",
    "    if len(subset) >= 10:\n",
    "        sample = subset.sample(n=10, random_state=42)\n",
    "    else:\n",
    "        sample = subset\n",
    "\n",
    "    # Append the sample DataFrame to the list\n",
    "    sampled_dfs.append(sample)\n",
    "\n",
    "# Concatenate all the sampled DataFrames into one DataFrame\n",
    "df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "252a5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a47b8045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Addition       1.00      0.25      0.40         4\n",
      "         Currency       0.50      1.00      0.67         3\n",
      "       Directions       1.00      1.00      1.00         3\n",
      "         Division       0.50      1.00      0.67         2\n",
      "        Fractions       1.00      0.75      0.86         4\n",
      " Length measuring       0.00      0.00      0.00         5\n",
      "   Multiplication       0.67      0.50      0.57         4\n",
      "  Number patterns       0.75      1.00      0.86         3\n",
      "          Numbers       0.50      0.50      0.50         2\n",
      "Shapes and Solids       0.67      0.67      0.67         3\n",
      "             Time       1.00      1.00      1.00         2\n",
      " Volume measuring       0.00      0.00      0.00         0\n",
      " Weight measuring       1.00      1.00      1.00         4\n",
      "\n",
      "         accuracy                           0.67        39\n",
      "        macro avg       0.66      0.67      0.63        39\n",
      "     weighted avg       0.70      0.67      0.65        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Question'], df['Category'], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Build a pipeline that first vectorizes the text with TF-IDF and then applies Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data.\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set.\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the classification performance report.\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9cd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as trained_pipeline.pkl\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(pipeline, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmath_classifier_1.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved as trained_pipeline.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Download the saved model file to your local system\u001b[39;00m\n\u001b[1;32m     10\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmath_classifier.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained pipeline to a file named \"trained_pipeline.pkl\"\n",
    "joblib.dump(pipeline, 'math_classifier_1.pkl')\n",
    "print(\"Model saved as trained_pipeline.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c45aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# data1 = 'csv_files/2021 - all.csv'\n",
    "# data2 = 'csv_files/2021 - 2020-1.csv'\n",
    "# data3 = 'csv_files/2021 - 2020-2.csv'\n",
    "# data4 = 'csv_files/2021 - 2021.csv'\n",
    "# data5 = 'csv_files/2021 - 2019 (2).csv'\n",
    "# data6 = 'csv_files/2021 - 2018 (1).csv'\n",
    "# data7 = 'csv_files/2021 - 2017.csv'\n",
    "# data8 = 'csv_files/2021 - 2016.csv'\n",
    "# data9 = 'csv_files/2021 - 2015.csv'\n",
    "\n",
    "\n",
    "# df1 = pd.read_csv(data1)\n",
    "# df2 = pd.read_csv(data2)\n",
    "# df3 = pd.read_csv(data3)\n",
    "# df4 = pd.read_csv(data4)\n",
    "# df5 = pd.read_csv(data5)\n",
    "# df6 = pd.read_csv(data6)\n",
    "# df7 = pd.read_csv(data7)\n",
    "# df8 = pd.read_csv(data8)\n",
    "# df9 = pd.read_csv(data9)\n",
    "\n",
    "# df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df[\"Category\"] == \"Sinhala grammar comprehension - NO\\n\", \"Category\"] = \"Sinhala language comprehension\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82087222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['Question', 'Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca306d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sinhala language comprehension',\n",
       "       'Common knowledge and logic reasoning', 'Mathematics',\n",
       "       'Sinhala grammar comprehension',\n",
       "       'Sinhala grammar comprehension - NO',\n",
       "       'English language and grammar comprehension',\n",
       "       'Tamil language and grammar comprehension', 'Environment', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ce2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63552224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "      Common knowledge and logic reasoning       0.70      0.39      0.50        18\n",
      "English language and grammar comprehension       0.67      0.67      0.67         3\n",
      "                               Environment       0.64      0.96      0.77        24\n",
      "                               Mathematics       0.59      0.83      0.69        12\n",
      "             Sinhala grammar comprehension       1.00      0.17      0.29         6\n",
      "        Sinhala grammar comprehension - NO       1.00      0.33      0.50         3\n",
      "            Sinhala language comprehension       0.50      0.46      0.48        13\n",
      "  Tamil language and grammar comprehension       1.00      0.80      0.89         5\n",
      "\n",
      "                                  accuracy                           0.64        84\n",
      "                                 macro avg       0.76      0.58      0.60        84\n",
      "                              weighted avg       0.68      0.64      0.61        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     df['Question'], df['Category'], test_size=0.3, random_state=42\n",
    "# )\n",
    "\n",
    "# # Build a pipeline that first vectorizes the text with TF-IDF and then applies Random Forest\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()),\n",
    "#     ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Train the pipeline on the training data.\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Predict labels for the test set.\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Print the classification performance report.\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f8646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Environment'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q = \"\"\"මහවැලි ගඟ සහ වලවේ ගඟ මුහුදට වැටෙන ස්ථාන දෙක පිළිවෙළින්,\n",
    "# (1) මඩකලපුව සහ අම්බලන්තොට වේ.\n",
    "# (2) මඩකලපුව සහ හම්බන්තොට වේ.\n",
    "# (3) ත්‍රිකුණාමලය සහ කතරගම වේ.\n",
    "# (4) ත්‍රිකුණාමලය සහ අම්බලන්තොට වේ.\n",
    "# \"\"\"\n",
    "\n",
    "# y_pred = pipeline.predict([q])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3517e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as cat_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained pipeline to a file named \"trained_pipeline.pkl\"\n",
    "joblib.dump(pipeline, 'cat_classifier_1.pkl')\n",
    "print(\"Model saved as cat_classifier.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     df['Question'], df['Category'], test_size=0.3, random_state=42\n",
    "# )\n",
    "\n",
    "# # Build a pipeline that first vectorizes the text with TF-IDF and then applies Random Forest\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()),\n",
    "#     ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Train the pipeline on the training data.\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Predict labels for the test set.\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Print the classification performance report.\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"\"\" සංඛ්‍යා රටාවේ හිස්තැන්වලට ආ යුතු සංඛ්‍යා ලියන්න: ______, ______, 100, 50, 25.\n",
    "# \"\"\"\n",
    "\n",
    "# y_pred = pipeline.predict([q])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Save the trained pipeline to a file named \"trained_pipeline.pkl\"\n",
    "# joblib.dump(pipeline, 'cat_classifier_1.pkl')\n",
    "# print(\"Model saved as trained_pipeline.pkl\")\n",
    "\n",
    "# # from google.colab import files\n",
    "\n",
    "# # # Download the saved model file to your local system\n",
    "# # files.download('math_classifier_1.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149423e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84e865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042c272",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'genai' from 'google' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m genai\n\u001b[1;32m      3\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGLE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'genai' from 'google' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/veo-2.0-generate-001\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client() # Get the key from the GOOGLE_API_KEY env variable\n",
    "\n",
    "for model_info in client.models.list():\n",
    "    print(model_info.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hussain vs. Jiffry case, also known as the \"Mosque Lands Case\", is a landmark legal battle in Sri Lanka that has profound implications for the country's religious and political landscape. Here's why it's important:\n",
      "\n",
      "**1. Dispute over Ownership and Control of Mosques:**\n",
      "   - The case revolves around the ownership and control of 1,000 acres of land in the Eastern Province, traditionally used by Muslims for mosques, graveyards, and other religious purposes.\n",
      "   - The land was originally granted to a Muslim philanthropist by the British colonial government in the 19th century.\n",
      "   - However, after Sri Lanka's independence, the government began claiming ownership of the land, citing legal technicalities and arguing that the original grant was invalid.\n",
      "\n",
      "**2. Impact on Muslim Religious Practices:**\n",
      "   - The outcome of the case directly affects the ability of Muslims in Sri Lanka to practice their religion freely and access sacred sites.\n",
      "   - If the government is declared the rightful owner, it could potentially restrict or control access to mosques and other religious properties.\n",
      "\n",
      "**3. Tensions between Muslim and Sinhalese Communities:**\n",
      "   - The case has become a symbol of ethnic and religious tensions in Sri Lanka.\n",
      "   - Many Muslims view the government's actions as an attempt to marginalize their community and undermine their religious rights.\n",
      "   - Sinhalese Buddhist nationalists, on the other hand, often support the government's position, seeing it as a way to assert Sinhalese dominance.\n",
      "\n",
      "**4. Legal Precedents and Interpretation of Land Laws:**\n",
      "   - The case has far-reaching implications for the interpretation of land laws in Sri Lanka, particularly those related to religious endowments and historical grants.\n",
      "   - The court's decision will set a precedent for future disputes over land ownership and religious institutions.\n",
      "\n",
      "**5. Political and Social Consequences:**\n",
      "   - The outcome of the case could influence political alliances and power dynamics in Sri Lanka.\n",
      "   - A victory for the Muslim community could strengthen their political voice and influence.\n",
      "   - Conversely, a government victory could embolden Sinhalese nationalist forces.\n",
      "\n",
      "**6. International Attention and Human Rights Concerns:**\n",
      "   - The case has attracted international attention due to its implications for religious freedom and minority rights in Sri Lanka.\n",
      "   - Human rights organizations have expressed concern over the potential for discrimination and marginalization of the Muslim community.\n",
      "\n",
      "**7. Ongoing Legal Battles and Uncertain Future:**\n",
      "   - The case has been ongoing for decades, with numerous court hearings and appeals.\n",
      "   - The final outcome remains uncertain, and the legal battle continues to shape religious and ethnic relations in Sri Lanka.\n",
      "\n",
      "In conclusion, the Hussain vs. Jiffry case is a pivotal legal battle with far-reaching consequences for Sri Lanka's religious, political, and social landscape. Its outcome will determine the future of Muslim religious practices, ethnic relations, and the interpretation of land laws in the country. The case continues to be a source of tension and uncertainty, highlighting the ongoing challenges to religious freedom and minority rights in Sri Lanka.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure your API Key\n",
    "# genai.configure(api_key=\"YOUR_GOOGLE_API_KEY\")\n",
    "\n",
    "# Load the model\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"tunedModels/generate-num-7045\",\n",
    ")\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(\"Explain the importance of Hussain vs. Jiffry case.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01650cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuning_job' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m response = client.models.generate_content(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     model=\u001b[43mtuning_job\u001b[49m.tuned_model.model,\n\u001b[32m      3\u001b[39m     contents=\u001b[33m'\u001b[39m\u001b[33mIII\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'tuning_job' is not defined"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=tuning_job.tuned_model.model,\n",
    "    contents='III',\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d15720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Environment'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
